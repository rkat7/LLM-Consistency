import logging
import time
from typing import Dict, List, Optional, Tuple, Set, Any, Union
from enum import Enum
import z3
import sympy
import re
from ..config.config import Config
from ..models.logic_model import LogicalRule, Formula, LogicalOperator
from collections import deque, defaultdict

# Configure logging
logging.basicConfig(
    level=getattr(logging, Config.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(Config.LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class VerificationResult:
    """Result of a verification process."""
    
    def __init__(self, is_consistent: bool, inconsistencies: List[str] = None, proof: str = None):
        self.is_consistent = is_consistent
        self.inconsistencies = inconsistencies or []
        self.proof = proof
        self.verification_time = None
    
    def __str__(self) -> str:
        if self.is_consistent:
            return f"Verification Result: Consistent (time: {self.verification_time:.2f}s)"
        else:
            inconsistencies_str = "\n  ".join(self.inconsistencies)
            return f"Verification Result: Inconsistent (time: {self.verification_time:.2f}s)\nInconsistencies:\n  {inconsistencies_str}"

class SolverType(str, Enum):
    """Types of solvers supported."""
    Z3 = "z3"
    SYMPY = "sympy"

class VerificationEngine:
    """Engine for verifying logical consistency."""
    
    def __init__(self, solver_type: str = Config.SOLVER_TYPE):
        """Initialize the verification engine."""
        self.solver_type = SolverType(solver_type)
        logger.info(f"Verification Engine initialized with solver: {solver_type}")
    
    def verify(self, text):
        """
        Verify the logical consistency of the given text.

        Args:
            text (str): The text to verify for logical consistency.

        Returns:
            VerificationResult: The result of the verification.
        """
        logger.info("[FLOW:VERIFY] Starting verification process")
        
        # Preprocess and split into statements
        statements = self._preprocess_text(text)
        logger.info(f"[FLOW:VERIFY] Extracted {len(statements)} statements")
        
        # Run rule extraction methods
        extracted_rules = []
        
        # Check for class/instance relationships
        result = self._check_class_instance_contradictions(statements)
        if not result.is_consistent:
            logger.info(f"[FLOW:VERIFY] Detected contradiction in class/instance relationships: {result.explanation}")
            return result
        
        # Extract rules from statements
        extracted_rules = self._extract_rules(statements)
        
        # Process same relationships
        result = self._handle_same_relationship(statements, extracted_rules)
        
        # If a VerificationResult was returned, it means a contradiction was found
        if isinstance(result, VerificationResult):
            logger.info(f"[FLOW:VERIFY] Detected contradiction in same relationships: {result.explanation}")
        return result
        
        extracted_rules = result  # Update rules with the ones returned from _handle_same_relationship
        
        # Check for equality contradictions
        result = self._check_equality_contradictions(statements)
        if not result.is_consistent:
            logger.info(f"[FLOW:VERIFY] Detected contradiction in equality relationships: {result.explanation}")
            return result
        
        # If we have Z3 available, use it for more advanced verification
        if self.use_z3:
            logger.info("[FLOW:VERIFY] Using Z3 for formal verification")
            z3_result = self._verify_with_z3(statements, extracted_rules)
            if not z3_result.is_consistent:
                return z3_result
        
        # If no contradictions found, return consistent result
        logger.info("[FLOW:VERIFY] No contradictions found, text is logically consistent")
        return VerificationResult(
            is_consistent=True,
            explanation="The text is logically consistent. No contradictions were found."
        )
        
    def _preprocess_text(self, text):
        """
        Preprocess the input text for verification.
        
        Args:
            text: The text to preprocess
            
        Returns:
            str: The preprocessed text
        """
        logger.info("[FLOW:PREPROCESS] Preprocessing text")
        
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text.strip())
        
        # Normalize punctuation
        text = text.replace(';', '.')
        
        # Ensure proper spacing after periods
        text = re.sub(r'\.(?=[A-Za-z])', '. ', text)
        
        return text
        
    def _split_into_statements(self, text):
        """
        Split the text into individual statements for verification.
        
        Args:
            text: The text to split
            
        Returns:
            list: List of individual statements
        """
        logger.info("[FLOW:SPLIT] Splitting text into statements")
        
        # Split by period followed by space or end of string
        statements = re.split(r'\.(?:\s+|$)', text)
        
        # Remove empty statements and strip whitespace
        statements = [s.strip() for s in statements if s.strip()]
        
        # Add periods back to statements
        statements = [f"{s}." for s in statements]
        
        return statements
    
    def _check_no_pattern_inconsistencies(self, statements):
        """
        Check for inconsistencies involving "No X are Y" patterns.
        E.g., "No planets are stars" vs "Earth is a planet and Earth is a star"
        
        Args:
            statements: List of natural language statements
            
        Returns:
            VerificationResult if inconsistency found, None otherwise
        """
        logger.info("[FLOW:NO_PATTERN] Checking for no-pattern inconsistencies")
        
        # Pattern to match "No X are Y" statements
        no_pattern = re.compile(r"No\s+(\w+)\s+(?:are|is)\s+(\w+)", re.IGNORECASE)
        
        # Extract all "No X are Y" statements
        no_statements = []
        for statement in statements:
            match = no_pattern.search(statement)
            if match:
                class_name = match.group(1).lower()
                excluded_class = match.group(2).lower()
                no_statements.append((class_name, excluded_class, statement))
        
        # For each "No X are Y" statement, check if there's an instance that belongs to both X and Y
        for class_name, excluded_class, no_statement in no_statements:
            # Look for instances of class_name
            instances = []
            for statement in statements:
                instance_pattern = re.compile(rf"(\w+)\s+is\s+(?:a|an)?\s*{class_name}", re.IGNORECASE)
                instance_match = instance_pattern.search(statement)
                if instance_match:
                    instance = instance_match.group(1).lower()
                    instances.append((instance, statement))
            
            # For each instance, check if it's also claimed to be in the excluded class
            for instance, instance_statement in instances:
                excluded_instance_pattern = re.compile(rf"{instance}\s+is\s+(?:a|an)?\s*{excluded_class}", re.IGNORECASE)
                for statement in statements:
                    if excluded_instance_pattern.search(statement):
                        logger.info(f"[FLOW:NO_PATTERN] Found no-pattern inconsistency: '{no_statement}', '{instance_statement}', '{statement}'")
                        return VerificationResult(
                            is_consistent=False,
                            contradiction_type="no_pattern_contradiction",
                            contradicting_statements=[no_statement, instance_statement, statement],
                            explanation=f"Inconsistency: '{no_statement}' states that no {class_name} can be {excluded_class}, but '{instance}' is both a {class_name} and a {excluded_class}."
                        )
        
        logger.info("[FLOW:NO_PATTERN] No no-pattern inconsistencies found")
        return None
    
    def _normalize_proposition(self, text: str) -> str:
        """Normalize proposition text for consistent Z3 variable naming."""
        if not text: return "invalid_proposition"
        original_text = text
        text = text.lower().strip()
        
        is_universal = False
        if text.startswith("all "):
            is_universal = True
            text = text[4:]

        # Handle negations carefully to form consistent units (e.g., "can not fly" -> "cannot_fly")
        text = re.sub(r'\b(can|cannot|can\'t)\s+not\s+fly\b', 'cannot_fly', text)
        text = re.sub(r'\b(does|doesn\'t)\s+not\s+fly\b', 'doesnot_fly', text)
        text = re.sub(r'\b(is|isn\'t)\s+not\s+(\w+)', r'isnot_\2', text)
        text = re.sub(r'\b(are|aren\'t)\s+not\s+(\w+)', r'isnot_\2', text) # Treat are not as is not for singular form
        # General negation pattern AFTER specific ones
        text = re.sub(r'\bnot\s+(\w+)', r'not_\1', text)

        # Handle positive verbs/modal verbs + verb
        text = re.sub(r'\bcan\s+fly\b', 'can_fly', text)
        text = re.sub(r'\b(is|are)\s+flying\b', 'is_flying', text)
        text = re.sub(r'\b(has|have)\s+fur\b', 'has_fur', text)
        
        # Normalize simple verbs/predicates
        text = re.sub(r'\s+are\b', ' is', text)
        text = re.sub(r'\s+have\b', ' has', text)
        text = re.sub(r'\s+fly\b', ' fly', text) # Keep base form for simple fly

        # Basic plural subject normalization (attempt to make singular)
        # Do this *before* converting spaces to underscores
        text = re.sub(r'(\w+)s\s+(is|has|fly|can_fly)\b', r'\1 \2', text)
        text = re.sub(r'(\w+)es\s+(is|has|fly|can_fly)\b', r'\1 \2', text)
        text = re.sub(r'(\w+)ies\s+(is|has|fly|can_fly)\b', r'\1y \2', text)  

        # Remove articles 
        text = re.sub(r'\b(a|an|the|some)\b', '', text)
        text = re.sub(r'\s+', ' ', text).strip() # Normalize spaces
        
        # Final conversion to snake_case for Z3 variable names
        text = re.sub(r'\s+', '_', text)
        text = re.sub(r'[^a-z0-9_]', '', text) # Keep only alphanum and underscore

        # Add back universal prefix if needed
        if is_universal:
            text = f"all_{text}"
        
        if not text:
             logger.warning(f"Normalization resulted in empty string for: '{original_text}'")
             return "invalid_proposition"
             
        return text
    
    def _parse_negated_statement(self, statement: str) -> Optional[Dict[str, Any]]:
        """Parse negated statement into subject, predicate, and positive form."""
        statement = statement.strip()
        # Try "NOT (assertion)" format first
        match_not = re.match(r'not\s*\((.+)\)', statement, re.IGNORECASE)
        if match_not:
            positive_form = match_not.group(1).strip()
            # Attempt to further parse the positive form if needed
            parts = re.match(r'(.+?)\s+(?:is|are)\s+(.+)', positive_form, re.IGNORECASE)
            subject = parts.group(1).strip() if parts else None
            predicate = parts.group(2).strip() if parts else None
            return {"subject": subject, "predicate": predicate, "positive_form": positive_form}

        # Try "subject is not predicate" format
        parts = re.match(r'(.+?)\s+(is not|are not|cannot|doesn\'t|does not|don\'t|do not)\s+(.+)', statement, re.IGNORECASE)
        if parts:
            subject = parts.group(1).strip()
            predicate = parts.group(3).strip()
             # Handle cases like "cannot fly" -> predicate is "fly", verb is "can"
            verb = parts.group(2).strip()
            if verb in ["cannot", "can't"]:
                 positive_verb = "can"
            elif verb in ["doesn't", "does not"]:
                 positive_verb = "does" # Or reconstruct verb based on subject? Simpler: use base form
                 positive_form = f"{subject} {predicate}" # e.g. "bird fly"
            else:
                 positive_verb = "is" # Default reconstruction

            # Attempt a reasonable positive form construction
            if positive_verb == "is":
                 positive_form = f"{subject} is {predicate}"
            elif positive_verb == "can":
                 positive_form = f"{subject} can {predicate}"
            else:
                 # Fallback if verb reconstruction is complex
                 positive_form = f"{subject} {predicate}"

            return {"subject": subject, "predicate": predicate, "positive_form": positive_form}

        logger.warning(f"Could not parse negation format: {statement}")
        return None
    
    def _parse_universal_statement(self, statement: str) -> Optional[Dict[str, str]]:
        """Parse universal statement like 'All X are Y' or 'Every X has Y'."""
        # Pattern: All/Every X are/is/has Y
        match = re.match(r'(?:all|every)\s+(.+?)\s+(?:are|is|has)\s+(.+)', statement, re.IGNORECASE)
        if match:
            subject = match.group(1).strip()
            predicate = match.group(2).strip()
            # Construct a representative assertion, e.g., "X is Y"
            # More complex semantics (∀x P(x) → Q(x)) are not handled here
            rep_assertion = f"{subject} is {predicate}"
            return {"subject": subject, "predicate": predicate, "representative_assertion": rep_assertion}
        return None
    
    def _formalize_rules(self, rules: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Convert parsed rules into propositions and map them to unique IDs."""
        propositions_map = {} # Map normalized prop text -> unique index
        propositions_list = [] # List to hold unique normalized prop text in order
        next_prop_index = 0
        processed_rules = []

        def get_or_create_prop_index(prop_text: str) -> Optional[int]:
            nonlocal next_prop_index
            logger.debug(f"Formalizing proposition text: '{prop_text}'") # Log input
            normalized_prop = self._normalize_proposition(prop_text)
            logger.debug(f"  -> Normalized: '{normalized_prop}'") # Log normalized
            
            if normalized_prop == "invalid_proposition":
                logger.debug("  -> Result: Invalid Proposition")
                return None
            
            if normalized_prop not in propositions_map:
                assigned_index = next_prop_index
                propositions_map[normalized_prop] = assigned_index
                propositions_list.append(normalized_prop)
                next_prop_index += 1
                logger.debug(f"  -> Result: NEW Index {assigned_index}") # Log new index
            else:
                assigned_index = propositions_map[normalized_prop]
                logger.debug(f"  -> Result: EXISTING Index {assigned_index}") # Log existing index
                
            return assigned_index

        for rule in rules:
            processed_rule = rule.copy()
            rule_type = rule["type"]

            try:
                if rule_type == "implication":
                    antecedent_idx = get_or_create_prop_index(rule["antecedent"])
                    consequent_idx = get_or_create_prop_index(rule["consequent"])
                    processed_rule["antecedent_idx"] = antecedent_idx
                    processed_rule["consequent_idx"] = consequent_idx
                elif rule_type == "assertion":
                    prop_idx = get_or_create_prop_index(rule["statement"])
                    processed_rule["prop_idx"] = prop_idx
                elif rule_type == "negation":
                    positive_statement = rule.get("statement")
                    if positive_statement:
                        prop_idx = get_or_create_prop_index(positive_statement)
                        processed_rule["prop_idx"] = prop_idx
                    else:
                         logger.warning(f"Negation rule missing 'statement': {rule.get('original_text')}")
                         processed_rule["prop_idx"] = None
                elif rule_type == "universal":
                     positive_statement = rule.get("statement")
                     if positive_statement:
                         prop_idx = get_or_create_prop_index(positive_statement)
                         processed_rule["prop_idx"] = prop_idx
                     else:
                         logger.warning(f"Universal rule missing 'statement': {rule.get('original_text')}")
                         processed_rule["prop_idx"] = None
                else:
                     processed_rule["prop_idx"] = None
                     if rule_type == "implication": # Ensure implication indices are None if props invalid
                         if processed_rule.get("antecedent_idx") is None or processed_rule.get("consequent_idx") is None:
                             processed_rule["antecedent_idx"] = None
                             processed_rule["consequent_idx"] = None

            except Exception as e:
                logger.error(f"Error formalizing rule '{rule.get('original_text', rule)}': {e}")
                processed_rule["prop_idx"] = None
                if rule_type == "implication":
                    processed_rule["antecedent_idx"] = None
                    processed_rule["consequent_idx"] = None

            processed_rules.append(processed_rule)

        formalized = {
            "propositions_list": propositions_list,
            "propositions_map": propositions_map,
            "rules": processed_rules
        }

        logger.debug(f"Found {len(propositions_list)} unique propositions.")
        return formalized
    
    def _verify_with_z3(self, rules: List[Dict[str, Any]], original_texts: Optional[List[str]] = None) -> VerificationResult:
        """Verify the consistency of rules using Z3 solver."""
        logger.info("[FLOW:Z3] Starting Z3 verification")
        
        solver = z3.Solver()
        
        # Create Z3 boolean variables for each entity
        entities = set()
        entity_vars = {}
        propositions = {}
        
        for rule in rules:
            entities.update(rule["entities"])
        
        logger.info(f"[FLOW:Z3] Found {len(entities)} entities in rules")
        
        # Create Z3 boolean variables for each entity
        for entity in entities:
            entity_vars[entity] = z3.Bool(entity)
            logger.debug(f"[FLOW:Z3] Created variable for entity: '{entity}'")

        # Check for "No X are Y" statements and handle them specifically
        if original_texts:
            # Enhanced pattern to match "No X are Y" statements with more flexibility
            no_pattern = re.compile(r"No\s+(\w+?)s?\s+(?:are|is)\s+(\w+?)s?(?:\.|\s|$)", re.IGNORECASE)
            
            for text in original_texts:
                match = no_pattern.search(text)
                if match:
                    class_name = match.group(1).lower()
                    excluded_class = match.group(2).lower()
                    logger.debug(f"[FLOW:Z3] Found 'No X are Y' statement: No {class_name} are {excluded_class}")
                    
                    # Enhanced pattern to match "Z is [a/an] X" with more flexibility
                    instance_pattern = re.compile(rf"(\w+)\s+is\s+(?:a|an)?\s*{re.escape(class_name)}(?:\.|\s|$)", re.IGNORECASE)
                    instances = []
                    
                    # Collect all instances of the class from original statements
                    for rule_text in original_texts:
                        for instance_match in instance_pattern.finditer(rule_text):
                            instance = instance_match.group(1).lower()
                            instances.append((instance, rule_text))
                            logger.debug(f"[FLOW:Z3] Found instance of {class_name}: {instance}")
                    
                    # For each instance, check if it's also claimed to be part of the excluded class
                    for instance, instance_statement in instances:
                        # Enhanced pattern to match "Z is [a/an] Y" with more flexibility
                        excluded_instance_pattern = re.compile(rf"{re.escape(instance)}\s+is\s+(?:a|an)?\s*{re.escape(excluded_class)}(?:\.|\s|$)", re.IGNORECASE)
                        
                        for statement in original_texts:
                            if excluded_instance_pattern.search(statement):
                                logger.info(f"[FLOW:Z3] Found contradiction: '{text}', '{instance_statement}', '{statement}'")
                                
                                return VerificationResult(
                                    is_consistent=False,
                                    inconsistencies=[
                                        f"Statement '{text}' claims that no {class_name} can be a {excluded_class}.",
                                        f"Statement '{instance_statement}' claims that {instance} is a {class_name}.",
                                        f"Statement '{statement}' claims that {instance} is a {excluded_class}."
                                    ],
                                    proof=f"Contradiction found: '{text}' and '{instance_statement}' and '{statement}' are logically inconsistent."
                                )
        
        # Convert rules to Z3 constraints
        for rule in rules:
            rule_type = rule["type"]
            
            logger.debug(f"[FLOW:Z3] Processing rule of type: {rule_type}")
            
            if rule_type == "proposition":
                entity = rule["entities"][0]
                value = rule["value"]
                
                # Check if the entity exists in our variable map
                if entity not in entity_vars:
                    logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping rule")
                    continue
                    
                var = entity_vars[entity]
                if value:
                    logger.debug(f"[FLOW:Z3] Adding constraint: {entity} is TRUE")
                    solver.add(var)
                else:
                    logger.debug(f"[FLOW:Z3] Adding constraint: {entity} is FALSE")
                    solver.add(z3.Not(var))
                propositions[entity] = value
                
            elif rule_type == "implication":
                antecedent = rule["antecedent"]
                consequent = rule["consequent"]
                
                # Convert antecedent to Z3 formula
                if antecedent["type"] == "AND":
                    ant_terms = []
                    for entity in antecedent["entities"]:
                        if entity not in entity_vars:
                            logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping from antecedent")
                            continue
                        ant_terms.append(entity_vars[entity])
                    ant_formula = z3.And(*ant_terms) if ant_terms else None
                elif antecedent["type"] == "OR":
                    ant_terms = []
                    for entity in antecedent["entities"]:
                        if entity not in entity_vars:
                            logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping from antecedent")
                            continue
                        ant_terms.append(entity_vars[entity])
                    ant_formula = z3.Or(*ant_terms) if ant_terms else None
                else:  # Single entity
                    entity = antecedent["entities"][0]
                    if entity not in entity_vars:
                        logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping rule")
                        continue
                    ant_formula = entity_vars[entity]
                
                # Convert consequent to Z3 formula
                if consequent["type"] == "AND":
                    cons_terms = []
                    for entity in consequent["entities"]:
                        if entity not in entity_vars:
                            logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping from consequent")
                            continue
                        cons_terms.append(entity_vars[entity])
                    cons_formula = z3.And(*cons_terms) if cons_terms else None
                elif consequent["type"] == "OR":
                    cons_terms = []
                    for entity in consequent["entities"]:
                        if entity not in entity_vars:
                            logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping from consequent")
                            continue
                        cons_terms.append(entity_vars[entity])
                    cons_formula = z3.Or(*cons_terms) if cons_terms else None
                else:  # Single entity
                    entity = consequent["entities"][0]
                    if entity not in entity_vars:
                        logger.warning(f"[FLOW:Z3] Entity '{entity}' not found in variable map, skipping rule")
                        continue
                    cons_formula = entity_vars[entity]
                
                # Skip if either formula is None due to missing entities
                if ant_formula is None or cons_formula is None:
                    logger.warning("[FLOW:Z3] Skipping rule due to missing entities")
                    continue
                
                # Add implication to solver
                logger.debug(f"[FLOW:Z3] Adding implication: {antecedent} => {consequent}")
                solver.add(z3.Implies(ant_formula, cons_formula))
                
            elif rule_type == "equality":
                entity1, entity2 = rule["entities"]
                
                # Check if both entities exist in our variable map
                if entity1 not in entity_vars or entity2 not in entity_vars:
                    logger.warning(f"[FLOW:Z3] Entities '{entity1}' or '{entity2}' not found in variable map, skipping rule")
                    continue
                    
                var1 = entity_vars[entity1]
                var2 = entity_vars[entity2]
                
                # Add equality constraint: entity1 iff entity2
                logger.debug(f"[FLOW:Z3] Adding equality constraint: {entity1} ⟷ {entity2}")
                solver.add(var1 == var2)
                
            elif rule_type == "class_instance":
                class_name = rule["class_name"]
                instance_name = rule["instance_name"]
                
                # Check if both class and instance exist in our variable map
                if class_name not in entity_vars or instance_name not in entity_vars:
                    logger.warning(f"[FLOW:Z3] Class '{class_name}' or instance '{instance_name}' not found in variable map, skipping rule")
                    continue
                    
                class_var = entity_vars[class_name]
                instance_var = entity_vars[instance_name]
                
                # Add implication: instance implies class
                logger.debug(f"[FLOW:Z3] Adding class-instance constraint: {instance_name} => {class_name}")
                solver.add(z3.Implies(instance_var, class_var))
                
            else:
                logger.warning(f"[FLOW:Z3] Unhandled rule type: {rule_type}")
        
        # Check for satisfiability
        logger.info("[FLOW:Z3] Checking satisfiability")
        result = solver.check()

        if result == z3.sat:
            logger.info("[FLOW:Z3] Rules are satisfiable (consistent)")
            model = solver.model()
            
            # Get the values of all entities
            entity_values = {}
            for entity, var in entity_vars.items():
                if model[var] is not None:
                    value = z3.is_true(model[var])
                    entity_values[entity] = value
                    logger.debug(f"[FLOW:Z3] Entity '{entity}' = {value}")
            
            return VerificationResult(
                is_consistent=True,
                message="The statements are consistent.",
                details={
                    "satisfiable": True,
                    "model": entity_values
                }
            )
        else:
            logger.info("[FLOW:Z3] Rules are unsatisfiable (inconsistent)")
            
            # Try to extract an unsat core if available
            if hasattr(solver, 'unsat_core'):
                core = solver.unsat_core()
                logger.debug(f"[FLOW:Z3] Unsat core contains {len(core)} constraints")
                
                # Extract the relevant entities from the unsat core
                core_entities = set()
                for constraint in core:
                    for entity, var in entity_vars.items():
                        if str(var) in str(constraint):
                            core_entities.add(entity)
                
                core_info = {
                    "entities": list(core_entities),
                    "constraints": [str(c) for c in core]
                }
            else:
                core_info = {"message": "Unsat core not available"}
            
            # Find related original statements
            related_statements = []
            if original_texts:
                for entity in core_entities:
                    for text in original_texts:
                        if re.search(r'\b' + re.escape(entity) + r'\b', text, re.IGNORECASE):
                            if text not in related_statements:
                                related_statements.append(text)
            
            return VerificationResult(
                is_consistent=False,
                message="The statements are inconsistent: one or more contradictions were found.",
                details={
                    "satisfiable": False,
                    "unsat_core": core_info,
                    "related_statements": related_statements
                }
            )

    def _verify_with_sympy(self, rules: List[Dict[str, Any]]) -> VerificationResult:
        """Verify logical consistency using SymPy."""
        # This is a placeholder implementation
        logger.warning("SymPy verification not fully implemented, falling back to Z3")
        return self._verify_with_z3(rules)

    def _verify_attribute_consistency(self, original_texts, rule_statements):
        """
        Verifies consistency of attribute statements, focusing on statements like:
        "A is true. B is true. A and B are same. C is A. C is not B."
        
        This handles cases where entities have attributes or are described with adjectives
        and we need to check for contradictions in how these attributes propagate.
        
        Args:
            original_texts (list): List of original text statements.
            rule_statements (list): List of formalized rule statements.
            
        Returns:
            VerificationResult or None: Result of verification, None if no contradiction found.
        """
        logger.info("[FLOW:REASONER:ATTRIBUTE] Starting attribute consistency verification")
        
        # Define patterns to capture attribute statements and entity relationships
        attribute_pattern = re.compile(r"([\w\s]+)\s+is\s+([\w\s]+)", re.IGNORECASE)
        same_as_pattern = re.compile(r"([\w\s]+)\s+(?:is the same as|are the same as|and)\s+([\w\s]+)\s+are\s+(?:the\s+)?same", re.IGNORECASE)
        not_same_pattern = re.compile(r"([\w\s]+)\s+is\s+not\s+([\w\s]+)", re.IGNORECASE)
        
        # Store entity attributes and relationships
        entity_attributes = defaultdict(set)  # Entity -> set of attributes
        entity_equivalences = defaultdict(set)  # Entity -> set of equivalent entities
        entity_differences = []  # List of (entity1, entity2) that are explicitly different
        
        for text in original_texts:
            text = text.strip()
            
            # Extract attribute statements: "A is true", "C is A"
            for match in attribute_pattern.finditer(text):
                entity = match.group(1).strip().lower()
                attribute = match.group(2).strip().lower()
                
                # Remove articles and clean entity names
                entity = re.sub(r'^(a|an|the)\s+', '', entity).strip()
                attribute = re.sub(r'^(a|an|the)\s+', '', attribute).strip()
                
                if entity and attribute:
                    entity_attributes[entity].add(attribute)
                    logger.debug(f"[FLOW:REASONER:ATTRIBUTE] Entity '{entity}' has attribute '{attribute}'")
            
            # Extract "same as" relationships: "A and B are same"
            for match in same_as_pattern.finditer(text):
                entity1 = match.group(1).strip().lower()
                entity2 = match.group(2).strip().lower()
                
                entity1 = re.sub(r'^(a|an|the)\s+', '', entity1).strip()
                entity2 = re.sub(r'^(a|an|the)\s+', '', entity2).strip()
                
                if entity1 and entity2:
                    entity_equivalences[entity1].add(entity2)
                    entity_equivalences[entity2].add(entity1)
                    logger.debug(f"[FLOW:REASONER:ATTRIBUTE] Entities '{entity1}' and '{entity2}' are equivalent")
            
            # Extract "not same" relationships: "C is not B"
            for match in not_same_pattern.finditer(text):
                entity1 = match.group(1).strip().lower()
                entity2 = match.group(2).strip().lower()
                
                entity1 = re.sub(r'^(a|an|the)\s+', '', entity1).strip()
                entity2 = re.sub(r'^(a|an|the)\s+', '', entity2).strip()
                
                if entity1 and entity2:
                    entity_differences.append((entity1, entity2))
                    logger.debug(f"[FLOW:REASONER:ATTRIBUTE] Entities '{entity1}' and '{entity2}' are different")
        
        # Build transitive closure of equivalences
        def find_all_equivalent(entity):
            visited = set([entity])
            queue = deque([entity])
            
            while queue:
                current = queue.popleft()
                for equivalent in entity_equivalences.get(current, set()):
                    if equivalent not in visited:
                        visited.add(equivalent)
                        queue.append(equivalent)
            
            return visited
        
        # Check for contradictions
        contradictions = []
        
        # For each entity, propagate its attributes to all equivalent entities
        for entity, attributes in entity_attributes.items():
            equivalent_entities = find_all_equivalent(entity)
            
            # Check each difference statement for contradictions
            for entity1, entity2 in entity_differences:
                # If entity1 and entity2 are supposed to be different, but they share
                # equivalent attributes through the equality relationship, that's a contradiction
                if (entity1 in equivalent_entities and entity2 in attributes) or \
                   (entity2 in equivalent_entities and entity1 in attributes):
                    contradiction = {
                        "entity1": entity1,
                        "entity2": entity2,
                        "path": list(equivalent_entities),
                        "shared_attribute": entity if entity1 in attributes or entity2 in attributes else None
                    }
                    contradictions.append(contradiction)
                    
                    logger.info(f"[FLOW:REASONER:ATTRIBUTE] Contradiction: '{entity1}' and '{entity2}' are stated to be different, but they share attribute/equivalence with '{entity}'")
        
        if contradictions:
            # Find the original statements for the first contradiction
            contra = contradictions[0]
            entity1, entity2 = contra["entity1"], contra["entity2"]
            
            # Collect statements showing equivalence
            equiv_statements = []
            for text in original_texts:
                if any(entity.lower() in text.lower() for entity in contra["path"]) and \
                   ("same" in text.lower() or "equal" in text.lower()):
                    equiv_statements.append(text)
            
            # Collect statements showing attribute relationships
            attr_statements = []
            for text in original_texts:
                if (entity1.lower() in text.lower() or entity2.lower() in text.lower()) and \
                   (contra["shared_attribute"] and contra["shared_attribute"].lower() in text.lower()):
                    attr_statements.append(text)
            
            # Collect statements showing difference
            diff_statements = []
            for text in original_texts:
                if entity1.lower() in text.lower() and entity2.lower() in text.lower() and \
                   ("not" in text.lower() or "different" in text.lower()):
                    diff_statements.append(text)
            
            message = f"Contradiction found in attribute statements: '{entity1}' and '{entity2}' are stated to be different, " \
                      f"but they share attributes or equivalences that make them the same."
                
            return VerificationResult(
                is_consistent=False,
                message=message,
                details={
                    "type": "attribute_contradiction",
                    "contradiction": contradictions[0],
                    "equivalence_statements": equiv_statements,
                    "attribute_statements": attr_statements,
                    "difference_statements": diff_statements
                }
            )
        
        logger.info("[FLOW:REASONER:ATTRIBUTE] No attribute contradictions found")
        return None

    def _optimize_pattern_matching(self, texts: List[str]) -> Dict[str, Any]:
        """
        Pre-process texts to optimize pattern matching efficiency.
        
        This method prepares the input texts for faster pattern matching by:
        1. Caching common regex patterns
        2. Pre-identifying entity mentions 
        3. Segmenting large paragraphs into smaller, manageable chunks
        
        Args:
            texts: List of text statements to analyze
            
        Returns:
            A dictionary containing optimized data structures for pattern matching
        """
        logger.info(f"[FLOW:OPTIMIZE] Pre-processing {len(texts)} statements for optimized pattern matching")
        
        # Initialize result data structures
        result = {
            "entity_mentions": defaultdict(list),  # Maps entities to statement indices
            "pattern_matches": defaultdict(list),  # Maps pattern types to matches
            "chunks": []  # Chunked statements for large paragraphs
        }
        
        # Extract all potential entities
        entities = set()
        entity_pattern = re.compile(r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\b')
        
        # First pass: Extract entities and build mention index
        for idx, text in enumerate(texts):
            # Extract potential entities (proper nouns)
            matches = entity_pattern.findall(text)
            for entity in matches:
                entities.add(entity)
                result["entity_mentions"][entity].append(idx)
            
            # For long paragraphs, split into sentences
            if len(text) > 100:
                sentences = re.split(r'(?<=[.!?])\s+', text)
                result["chunks"].extend([(idx, i, sentence) for i, sentence in enumerate(sentences)])
            else:
                result["chunks"].append((idx, 0, text))
        
        logger.debug(f"[FLOW:OPTIMIZE] Identified {len(entities)} potential entities and {len(result['chunks'])} text chunks")
        
        # Common patterns to cache
        patterns = {
            "equality": re.compile(r"(.*?)\s+(?:is|are)\s+(?:the\s+)?same\s+(?:as)?\s+(.*?)(?:$|\.|\,)", re.IGNORECASE),
            "inequality": re.compile(r"(.*?)\s+(?:is\s+not|are\s+not|isn'?t|aren'?t)\s+(.*?)(?:$|\.|\,)", re.IGNORECASE),
            "class_instance": re.compile(r"([\w\s]+?)\s+(?:is|are)\s+(?:a|an)?\s*(\w+)(?:\.|\s|$)", re.IGNORECASE),
            "no_pattern": re.compile(r"No\s+(\w+?)s?\s+(?:is|are)\s+(\w+?)s?(?:\.|\s|$)", re.IGNORECASE),
            "and_same": re.compile(r"(.*?)\s+and\s+(.*?)\s+are\s+(?:the\s+)?same", re.IGNORECASE)
        }
        
        # Second pass: Pre-compute pattern matches
        for chunk_idx, chunk_offset, chunk_text in result["chunks"]:
            for pattern_name, pattern in patterns.items():
                matches = pattern.findall(chunk_text)
                if matches:
                    for match in matches:
                        result["pattern_matches"][pattern_name].append({
                            "match": match,
                            "text_idx": chunk_idx,
                            "chunk_offset": chunk_offset,
                            "chunk_text": chunk_text
                        })
        
        logger.info(f"[FLOW:OPTIMIZE] Pre-computed {sum(len(v) for v in result['pattern_matches'].values())} pattern matches")
        return result
        
    def _check_classic_inconsistencies(self, statements):
        """
        Check for classic inconsistencies between statements, such as direct contradictions.
        
        Args:
            statements: List of natural language statements
            
        Returns:
            VerificationResult if inconsistency found, None otherwise
        """
        logger.info("[FLOW:CLASSIC] Checking for classic inconsistencies between statements")
        
        for i in range(len(statements)):
            for j in range(i + 1, len(statements)):
                statement1 = statements[i]
                statement2 = statements[j]
                
                if self._is_contradictory(statement1, statement2):
                    logger.info(f"[FLOW:CLASSIC] Found direct contradiction between '{statement1}' and '{statement2}'")
                    return VerificationResult(
                        is_consistent=False,
                        contradiction_type="direct_contradiction",
                        contradicting_statements=[statement1, statement2],
                        explanation=f"The statements '{statement1}' and '{statement2}' directly contradict each other."
                    )
                    
        logger.info("[FLOW:CLASSIC] No classic inconsistencies found")
        return None

    def _check_transitive_inconsistencies(self, statements):
        """
        Check for inconsistencies arising from transitive relationships.
        For example: "A and B are same. C is A. C is not B." creates a transitive inconsistency.
        
        Args:
            statements: List of natural language statements
            
        Returns:
            VerificationResult if inconsistency found, None otherwise
        """
        logger.info("[FLOW:TRANSITIVE] Checking for transitive inconsistencies")
        
        # Extract equivalence relations ("X and Y are same", "X is Y", etc.)
        equivalence_relations = []
        is_relations = []
        is_not_relations = []
        
        # Extract patterns
        for statement in statements:
            # Check for equivalence statements like "A and B are same"
            same_match = re.search(r"(.*) and (.*) (?:are|is) (?:the )?same", statement, re.IGNORECASE)
            if same_match:
                entity1, entity2 = same_match.group(1).strip(), same_match.group(2).strip()
                equivalence_relations.append((entity1, entity2, statement))
                continue
                
            # Check for "X is Y" patterns
            is_match = re.search(r"(.*) is (.*?)\.?$", statement, re.IGNORECASE)
            if is_match:
                entity1, entity2 = is_match.group(1).strip(), is_match.group(2).strip()
                is_relations.append((entity1, entity2, statement))
                continue
                
            # Check for "X is not Y" patterns
            is_not_match = re.search(r"(.*) is not (.*?)\.?$", statement, re.IGNORECASE)
            if is_not_match:
                entity1, entity2 = is_not_match.group(1).strip(), is_not_match.group(2).strip()
                is_not_relations.append((entity1, entity2, statement))
                
        # Check for transitive inconsistencies
        # For each equivalence relation, check if there's a statement that contradicts the equivalence
        for eq_entity1, eq_entity2, eq_statement in equivalence_relations:
            for is_entity1, is_entity2, is_statement in is_relations:
                # If X is A and A and B are same, then X should be B
                if is_entity2 == eq_entity1:
                    # Check if there's a statement saying X is not B
                    for not_entity1, not_entity2, not_statement in is_not_relations:
                        if not_entity1 == is_entity1 and not_entity2 == eq_entity2:
                            logger.info(f"[FLOW:TRANSITIVE] Found transitive inconsistency: '{eq_statement}', '{is_statement}', '{not_statement}'")
                            return VerificationResult(
                                is_consistent=False,
                                contradiction_type="transitive_contradiction",
                                contradicting_statements=[eq_statement, is_statement, not_statement],
                                explanation=f"Transitive inconsistency: '{is_entity1}' is '{eq_entity1}', '{eq_entity1}' and '{eq_entity2}' are the same, but '{is_entity1}' is not '{eq_entity2}'."
                            )
                
                # If X is B and A and B are same, then X should be A
                if is_entity2 == eq_entity2:
                    # Check if there's a statement saying X is not A
                    for not_entity1, not_entity2, not_statement in is_not_relations:
                        if not_entity1 == is_entity1 and not_entity2 == eq_entity1:
                            logger.info(f"[FLOW:TRANSITIVE] Found transitive inconsistency: '{eq_statement}', '{is_statement}', '{not_statement}'")
                            return VerificationResult(
                                is_consistent=False,
                                contradiction_type="transitive_contradiction",
                                contradicting_statements=[eq_statement, is_statement, not_statement],
                                explanation=f"Transitive inconsistency: '{is_entity1}' is '{eq_entity2}', '{eq_entity1}' and '{eq_entity2}' are the same, but '{is_entity1}' is not '{eq_entity1}'."
                            )
        
        logger.info("[FLOW:TRANSITIVE] No transitive inconsistencies found")
        return None

    def _check_negation_contradictions(self, rules, statements, optimized_data=None):
        """
        Check for contradictions based on negation patterns (No X are Y)
        
        Args:
            rules: List of extracted rules
            statements: Original natural language statements
            optimized_data: Pre-computed pattern matching data (optional)
            
        Returns:
            VerificationResult if a negation contradiction is found, None otherwise
        """
        logger.info("[FLOW:NEGATION] Starting negation contradiction check")
        
        # Extract negation patterns
        negation_patterns = {}  # Maps negation pattern to list of statements
        for i, stmt in enumerate(statements):
            for j in range(i + 1, len(statements)):
                if self._is_negation_contradiction(stmt, statements[j]):
                    pattern = self._extract_negation_pattern(stmt, statements[j])
                    if pattern:
                        if pattern not in negation_patterns:
                            negation_patterns[pattern] = []
                        negation_patterns[pattern].append((i, j))
        
        if negation_patterns:
            # Find the original statements for the first negation contradiction
            pattern, (i, j) = next(iter(negation_patterns.items()))
            entity1, entity2 = statements[i], statements[j]
            
            # Collect statements showing negation contradiction
            contradiction_statements = [entity1, entity2]
            
            message = f"Negation contradiction found: '{entity1}' and '{entity2}' are contradictory based on negation pattern: '{pattern}'"
            
            return VerificationResult(
                is_consistent=False,
                message=message,
                details={
                    "type": "negation_contradiction",
                    "contradiction": {
                        "pattern": pattern,
                        "contradicting_statements": contradiction_statements
                    }
                }
            )
        
        logger.info("[FLOW:NEGATION] No negation contradictions found")
        return None

    def _check_containment_contradictions(self, rules, statements):
        """
        Check for contradictions based on containment relationships between entities.
        
        Args:
            rules: List of extracted rules
            statements: Original natural language statements
            
        Returns:
            VerificationResult if a containment contradiction is found, None otherwise
        """
        logger.info("[FLOW:CONTAINMENT] Starting containment contradiction check")
        
        # Extract containment relationships
        containment_relationships = {}  # Maps container to contained entities
        for rule in rules:
            if rule["type"] == "implication" and rule["consequent"]["type"] == "AND":
                antecedent = rule["antecedent"]
                consequent = rule["consequent"]
                
                # Check if the consequent is a conjunction of entities
                if consequent["type"] == "AND":
                    for entity in consequent["entities"]:
                        if entity not in containment_relationships:
                            containment_relationships[entity] = set()
                        containment_relationships[entity].add(tuple(antecedent["entities"]))
        
        # Check for contradictions
        contradictions = []
        for container, contained in containment_relationships.items():
            for other_container, other_contained in containment_relationships.items():
                if container != other_container and contained.issubset(other_contained):
                    contradiction = {
                        "container": container,
                        "contained": contained,
                        "other_container": other_container,
                        "other_contained": other_contained
                    }
                    contradictions.append(contradiction)
        
        if contradictions:
            # Find the original statements for the first contradiction
            contra = contradictions[0]
            container, contained, other_container, other_contained = contra["container"], frozenset(contra["contained"]), contra["other_container"], frozenset(contra["other_contained"])
            
            # Collect statements showing containment
            container_statements = []
            for text in statements:
                if container.lower() in text.lower():
                    container_statements.append(text)
            
            container_info = {
                "container": container,
                "contained": list(contained),
                "other_container": other_container,
                "other_contained": list(other_contained)
            }
            
            message = f"Containment contradiction found: '{container}' contains '{contained}' which is also contained in '{other_container}'"
            
            return VerificationResult(
                is_consistent=False,
                message=message,
                details={
                    "type": "containment_contradiction",
                    "contradiction": {
                        "container": container_info,
                        "contained": container_info
                    },
                    "container_statements": container_statements
                }
            )
        
        logger.info("[FLOW:CONTAINMENT] No containment contradictions found")
        return None

    def _check_equality_contradictions(self, rules, statements, optimized_data=None):
        """
        Check for contradictions based on equality relationships between entities.
        This handles cases like: "A and B are the same. C is A. C is not B."
        
        Args:
            rules: List of extracted rules
            statements: Original natural language statements
            optimized_data: Pre-computed pattern matching data (optional)
            
        Returns:
            VerificationResult if a contradiction is found, None otherwise
        """
        logger.info("[FLOW:EQUALITY] Checking for equality-based contradictions")
        
        # Extract equality relationships
        equality_groups = {}  # Maps each entity to its equivalence group
        equivalence_classes = []  # List of sets, each set containing equivalent entities
        entity_attributes = defaultdict(set)  # Maps entity to its attributes
        entity_not_attributes = defaultdict(set)  # Maps entity to attributes it is explicitly not
        
        # Process explicit equality statements
        same_pattern = re.compile(r"(.+?)\s+and\s+(.+?)\s+are\s+(?:the\s+)?same", re.IGNORECASE)
        is_same_pattern = re.compile(r"(.+?)\s+(?:is|are)\s+(?:the\s+)?same\s+(?:as)?\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        
        # First pass: collect all equality relationships
        for stmt in statements:
            # Check for "A and B are same" pattern
            same_match = same_pattern.search(stmt)
            if same_match:
                entity1 = same_match.group(1).strip().lower()
                entity2 = same_match.group(2).strip().lower()
                
                # Find or create equivalence class
                found_class = False
                for eq_class in equivalence_classes:
                    if entity1 in eq_class or entity2 in eq_class:
                        eq_class.add(entity1)
                        eq_class.add(entity2)
                        found_class = True
                        break
                
                if not found_class:
                    equivalence_classes.append({entity1, entity2})
                
                logger.debug(f"[FLOW:EQUALITY] Found equality: {entity1} = {entity2}")
                
            # Check for "A is same as B" pattern
            is_same_match = is_same_pattern.search(stmt)
            if is_same_match and not same_match:  # Avoid double-counting
                entity1 = is_same_match.group(1).strip().lower()
                entity2 = is_same_match.group(2).strip().lower()
                
                # Find or create equivalence class
                found_class = False
                for eq_class in equivalence_classes:
                    if entity1 in eq_class or entity2 in eq_class:
                        eq_class.add(entity1)
                        eq_class.add(entity2)
                        found_class = True
                        break
                
                if not found_class:
                    equivalence_classes.append({entity1, entity2})
                
                logger.debug(f"[FLOW:EQUALITY] Found equality: {entity1} = {entity2}")
        
        # Second pass: merge equivalence classes
        # If class1 and class2 share an entity, merge them
        i = 0
        while i < len(equivalence_classes):
            j = i + 1
            merged = False
            while j < len(equivalence_classes):
                if equivalence_classes[i].intersection(equivalence_classes[j]):
                    equivalence_classes[i].update(equivalence_classes[j])
                    equivalence_classes.pop(j)
                    merged = True
                else:
                    j += 1
            if not merged:
                i += 1
        
        # Build the equality_groups map
        for i, eq_class in enumerate(equivalence_classes):
            for entity in eq_class:
                equality_groups[entity] = i
        
        logger.debug(f"[FLOW:EQUALITY] Found {len(equivalence_classes)} equivalence classes")
        
        # Process "is a" and "is not a" relationships
        is_pattern = re.compile(r"(.+?)\s+is\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        is_not_pattern = re.compile(r"(.+?)\s+is\s+not\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        
        # Collect positive relationships
        for i, stmt in enumerate(statements):
            is_match = is_pattern.search(stmt)
            if is_match and not is_not_pattern.search(stmt):  # Ensure it's not a negative statement
                subject = is_match.group(1).strip().lower()
                object_ = is_match.group(2).strip().lower()
                
                entity_attributes[subject].add((object_, stmt))
                logger.debug(f"[FLOW:EQUALITY] Entity {subject} is {object_}")
        
        # Collect negative relationships and check for contradictions
        for i, stmt in enumerate(statements):
            is_not_match = is_not_pattern.search(stmt)
            if is_not_match:
                subject = is_not_match.group(1).strip().lower()
                object_ = is_not_match.group(2).strip().lower()
                
                entity_not_attributes[subject].add((object_, stmt))
                logger.debug(f"[FLOW:EQUALITY] Entity {subject} is NOT {object_}")
                
                # Check for contradiction: entity is not X but it is equivalent to something that is X
                if subject in equality_groups:
                    subject_group = equality_groups[subject]
                    
                    # Find all entities in the same equivalence class
                    equivalent_entities = [entity for entity, group in equality_groups.items() 
                                          if group == subject_group]
                    
                    # Check if any equivalent entity has the attribute that subject is not supposed to have
                    for eq_entity in equivalent_entities:
                        for attr, attr_stmt in entity_attributes[eq_entity]:
                            if attr.lower() == object_.lower():
                                # Check if we're comparing directly to the equivalent entity
                                if eq_entity.lower() == object_.lower():
                                    logger.info(f"[FLOW:EQUALITY] Direct contradiction: {subject} is NOT {object_} but {subject} is equivalent to {eq_entity} which IS {object_}")
                                    
                                    # Find the statement that establishes the equivalence
                                    equivalence_stmt = None
                                    for eq_stmt in statements:
                                        if ((same_pattern.search(eq_stmt) and subject.lower() in eq_stmt.lower() and eq_entity.lower() in eq_stmt.lower()) or
                                            (is_same_pattern.search(eq_stmt) and subject.lower() in eq_stmt.lower() and eq_entity.lower() in eq_stmt.lower())):
                                            equivalence_stmt = eq_stmt
                                            break
                                    
                                    return VerificationResult(
                                        is_consistent=False,
                                        contradiction_type="equality_contradiction",
                                        contradicting_statements=[equivalence_stmt, attr_stmt, stmt],
                                        explanation=f"Contradiction: '{subject}' and '{eq_entity}' are stated to be the same, but '{subject}' is explicitly not '{object_}'."
                                    )
                                
                                # Transitivity check: A and B are same, C is A, C is not B
                                if attr.lower() == eq_entity.lower():
                                    logger.info(f"[FLOW:EQUALITY] Transitivity contradiction: {subject} is {eq_entity}, {eq_entity} is same as {object_}, but {subject} is not {object_}")
                                    
                                    # Find the statement that establishes the equivalence
                                    equivalence_stmt = None
                                    for eq_stmt in statements:
                                        if ((same_pattern.search(eq_stmt) and eq_entity.lower() in eq_stmt.lower() and object_.lower() in eq_stmt.lower()) or
                                            (is_same_pattern.search(eq_stmt) and eq_entity.lower() in eq_stmt.lower() and object_.lower() in eq_stmt.lower())):
                                            equivalence_stmt = eq_stmt
                                            break
                                    
                                    return VerificationResult(
                                        is_consistent=False,
                                        contradiction_type="transitivity_contradiction",
                                        contradicting_statements=[equivalence_stmt, attr_stmt, stmt],
                                        explanation=f"Transitivity contradiction: '{subject}' is '{rel_obj}', '{entity1}' and '{entity2}' are the same, but '{subject}' is not '{object_}'."
                                    )
        
        logger.info("[FLOW:EQUALITY] No equality-based contradictions found")
        return None

    def _is_contradictory(self, statement1, statement2):
        """
        Check if two statements directly contradict each other.
        
        Args:
            statement1: First statement
            statement2: Second statement
            
        Returns:
            bool: True if the statements are contradictory, False otherwise
        """
        # Direct negation check
        if statement1.lower() == "not " + statement2.lower() or statement2.lower() == "not " + statement1.lower():
            return True
            
        # Check for statements of the form "X is Y" and "X is not Y"
        is_pattern = re.compile(r"(\w+)\s+is\s+(\w+)", re.IGNORECASE)
        is_not_pattern = re.compile(r"(\w+)\s+is\s+not\s+(\w+)", re.IGNORECASE)
        
        is_match1 = is_pattern.search(statement1)
        is_not_match1 = is_not_pattern.search(statement1)
        is_match2 = is_pattern.search(statement2)
        is_not_match2 = is_not_pattern.search(statement2)
        
        # Check for "X is Y" and "X is not Y"
        if is_match1 and is_not_match2:
            subject1, attribute1 = is_match1.groups()
            subject2, attribute2 = is_not_match2.groups()
            if subject1.lower() == subject2.lower() and attribute1.lower() == attribute2.lower():
                return True
        
        if is_match2 and is_not_match1:
            subject2, attribute2 = is_match2.groups()
            subject1, attribute1 = is_not_match1.groups()
            if subject1.lower() == subject2.lower() and attribute1.lower() == attribute2.lower():
                return True
                
        return False
        
    def _is_transitive(self, statement1, statement2):
        """
        Check if two statements form a transitive relationship.
        
        Args:
            statement1: First statement
            statement2: Second statement
            
        Returns:
            bool: True if the statements form a transitive relationship, False otherwise
        """
        # Check for patterns like "X is Y", "Y is Z", and "X is not Z"
        is_pattern = re.compile(r"(\w+)\s+is\s+(\w+)", re.IGNORECASE)
        is_not_pattern = re.compile(r"(\w+)\s+is\s+not\s+(\w+)", re.IGNORECASE)
        
        is_match1 = is_pattern.search(statement1)
        is_match2 = is_pattern.search(statement2)
        
        if is_match1 and is_match2:
            subject1, attribute1 = is_match1.groups()
            subject2, attribute2 = is_match2.groups()
            
            # Check for transitive relationship X is Y, Y is Z
            if attribute1.lower() == subject2.lower():
                # Look for a third statement of the form "X is not Z"
                for stmt in self.all_statements:
                    is_not_match = is_not_pattern.search(stmt)
                    if is_not_match:
                        s, a = is_not_match.groups()
                        if s.lower() == subject1.lower() and a.lower() == attribute2.lower():
                            return True
        
        return False
        
    def _extract_negation_pattern(self, statement1, statement2):
        """
        Extract the negation pattern from two contradictory statements.
        
        Args:
            statement1: First statement
            statement2: Second statement
            
        Returns:
            str: The negation pattern if found, None otherwise
        """
        no_pattern = re.compile(r"No\s+(\w+)\s+are\s+(\w+)", re.IGNORECASE)
        is_pattern = re.compile(r"(\w+)\s+is\s+(?:a|an)?\s*(\w+)", re.IGNORECASE)
        
        no_match = no_pattern.search(statement1) or no_pattern.search(statement2)
        is_match = is_pattern.search(statement1) or is_pattern.search(statement2)
        
        if no_match and is_match:
            class_name, excluded_class = no_match.groups()
            instance, instance_class = is_match.groups()
            
            if class_name.lower() == instance_class.lower() and excluded_class.lower() == instance.lower():
                return f"No {class_name} are {excluded_class}, but {instance} is a {instance_class} and {instance} is {excluded_class}"
        
        return None
        
    def _is_negation_contradiction(self, statement1, statement2):
        """
        Check if two statements form a negation contradiction.
        
        Args:
            statement1: First statement
            statement2: Second statement
            
        Returns:
            bool: True if the statements form a negation contradiction, False otherwise
        """
        return self._extract_negation_pattern(statement1, statement2) is not None
        
    def _extract_rules(self, statements):
        """
        Extract logical rules from natural language statements.
        
        Args:
            statements: List of natural language statements
            
        Returns:
            List of rules extracted from the statements
        """
        # Store all statements for future reference in helper methods
        self.all_statements = statements
        
        rules = []
        for statement in statements:
            # Extract simple "is" statements
            is_pattern = re.compile(r"(\w+)\s+is\s+(\w+)", re.IGNORECASE)
            is_not_pattern = re.compile(r"(\w+)\s+is\s+not\s+(\w+)", re.IGNORECASE)
            
            is_match = is_pattern.search(statement)
            is_not_match = is_not_pattern.search(statement)
            
            if is_match:
                subject, attribute = is_match.groups()
                rule = {
                    "type": "atomic",
                    "subject": subject.lower(),
                    "predicate": "is",
                    "object": attribute.lower(),
                    "original_text": statement
                }
                rules.append(rule)
                
            if is_not_match:
                subject, attribute = is_not_match.groups()
                rule = {
                    "type": "atomic",
                    "subject": subject.lower(),
                    "predicate": "is_not",
                    "object": attribute.lower(),
                    "original_text": statement
                }
                rules.append(rule)
                
            # Extract equality statements
            same_pattern = re.compile(r"(\w+)\s+and\s+(\w+)\s+are\s+(?:the\s+)?same", re.IGNORECASE)
            same_match = same_pattern.search(statement)
            
            if same_match:
                entity1, entity2 = same_match.groups()
                rule = {
                    "type": "equality",
                    "entity1": entity1.lower(),
                    "entity2": entity2.lower(),
                    "original_text": statement
                }
                rules.append(rule)
                
            # Extract "No X are Y" statements
            no_pattern = re.compile(r"No\s+(\w+)\s+are\s+(\w+)", re.IGNORECASE)
            no_match = no_pattern.search(statement)
            
            if no_match:
                class_name, excluded_class = no_match.groups()
                rule = {
                    "type": "exclusion",
                    "class": class_name.lower(),
                    "excluded_class": excluded_class.lower(),
                    "original_text": statement
                }
                rules.append(rule)
                
        return rules 

    def _handle_same_relationship(self, statements, rules):
        """
        Handle 'same' relationships between entities.
        This detects patterns like "A and B are the same" or "A is the same as B"
        and creates appropriate logical equivalence rules.

        Args:
            statements (list): List of natural language statements
            rules (list): List of existing extracted rules

        Returns:
            Updated rules list with same/equal relationship rules added
        """
        logger.info("[FLOW:SAME] Processing 'same' relationships")
        
        # Create patterns to match both forms of same relationship
        and_same_pattern = re.compile(r"(.+?)\s+and\s+(.+?)\s+are\s+(?:the\s+)?same", re.IGNORECASE)
        is_same_pattern = re.compile(r"(.+?)\s+(?:is|are)\s+(?:the\s+)?same\s+(?:as)?\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        
        # Track equality relationships for easier contradiction detection
        equality_pairs = []
        
        # Look for "A and B are same" pattern
        for stmt in statements:
            and_same_match = and_same_pattern.search(stmt)
            if and_same_match:
                entity1 = and_same_match.group(1).strip()
                entity2 = and_same_match.group(2).strip()
                
                # Create bidirectional equality rules
                rule1 = f"{entity1} = {entity2}"
                rule2 = f"{entity2} = {entity1}"
                
                if rule1 not in rules:
                    rules.append(rule1)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule1}")
                
                if rule2 not in rules:
                    rules.append(rule2)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule2}")
                
                equality_pairs.append((entity1, entity2, stmt))
        
        # Look for "A is same as B" pattern
        for stmt in statements:
            is_same_match = is_same_pattern.search(stmt)
            if is_same_match and not and_same_pattern.search(stmt):  # Avoid double-counting
                entity1 = is_same_match.group(1).strip()
                entity2 = is_same_match.group(2).strip()
                
                # Create bidirectional equality rules
                rule1 = f"{entity1} = {entity2}"
                rule2 = f"{entity2} = {entity1}"
                
                if rule1 not in rules:
                    rules.append(rule1)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule1}")
                
                if rule2 not in rules:
                    rules.append(rule2)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule2}")
                
                equality_pairs.append((entity1, entity2, stmt))
        
        # Now check for simple is/is not relationships to find contradictions
        is_pattern = re.compile(r"(.+?)\s+is\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        is_not_pattern = re.compile(r"(.+?)\s+is\s+not\s+(.+?)(?:$|\.|\,)", re.IGNORECASE)
        
        # Track entity relationships
        entity_relations = {}
        entity_non_relations = {}
        
        # Process positive relationships
        for stmt in statements:
            is_match = is_pattern.search(stmt)
            if is_match and not is_not_pattern.search(stmt):  # Make sure it's not a negative statement
                subject = is_match.group(1).strip()
                object_ = is_match.group(2).strip()
                
                if subject not in entity_relations:
                    entity_relations[subject] = []
                entity_relations[subject].append((object_, stmt))
                
                # Add appropriate rule
                rule = f"{subject} is {object_}"
                if rule not in rules:
                    rules.append(rule)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule}")
        
        # Process negative relationships and check directly for contradictions
        for stmt in statements:
            is_not_match = is_not_pattern.search(stmt)
            if is_not_match:
                subject = is_not_match.group(1).strip()
                object_ = is_not_match.group(2).strip()
                
                if subject not in entity_non_relations:
                    entity_non_relations[subject] = []
                entity_non_relations[subject].append((object_, stmt))
                
                # Add negative rule
                rule = f"{subject} is not {object_}"
                if rule not in rules:
                    rules.append(rule)
                    logger.debug(f"[FLOW:SAME] Added rule: {rule}")
                
                # Check for direct contradiction with previously added rules
                if subject in entity_relations:
                    for rel_obj, rel_stmt in entity_relations[subject]:
                        if rel_obj.lower() == object_.lower():
                            logger.info(f"[FLOW:SAME] Direct contradiction: {subject} is {object_} but also is not {object_}")
                            
                            return VerificationResult(
                                is_consistent=False,
                                contradiction_type="direct_contradiction",
                                contradicting_statements=[rel_stmt, stmt],
                                explanation=f"Direct contradiction: '{subject}' is stated to be '{object_}' and also stated to not be '{object_}'."
                            )
                
                # Check for equality-based contradictions
                for entity1, entity2, eq_stmt in equality_pairs:
                    # Case 1: subject = entity1, object_ = entity2
                    if subject.lower() == entity1.lower() and object_.lower() == entity2.lower():
                        logger.info(f"[FLOW:SAME] Equality contradiction: {subject} is not {object_} but {entity1} and {entity2} are the same")
                        
                        return VerificationResult(
                            is_consistent=False,
                            contradiction_type="equality_contradiction",
                            contradicting_statements=[eq_stmt, stmt],
                            explanation=f"Equality contradiction: '{entity1}' and '{entity2}' are stated to be the same, but '{subject}' is explicitly not '{object_}'."
                        )
                    
                    # Case 2: subject = entity2, object_ = entity1
                    if subject.lower() == entity2.lower() and object_.lower() == entity1.lower():
                        logger.info(f"[FLOW:SAME] Equality contradiction: {subject} is not {object_} but {entity1} and {entity2} are the same")
                        
                        return VerificationResult(
                            is_consistent=False,
                            contradiction_type="equality_contradiction",
                            contradicting_statements=[eq_stmt, stmt],
                            explanation=f"Equality contradiction: '{entity1}' and '{entity2}' are stated to be the same, but '{subject}' is explicitly not '{object_}'."
                        )
                    
                    # Case 3: Transitivity - C is A, C is not B, A and B are same
                    if subject in entity_relations:
                        for rel_obj, rel_stmt in entity_relations[subject]:
                            if ((rel_obj.lower() == entity1.lower() and object_.lower() == entity2.lower()) or
                                (rel_obj.lower() == entity2.lower() and object_.lower() == entity1.lower())):
                                
                                logger.info(f"[FLOW:SAME] Transitivity contradiction: {subject} is {rel_obj}, {rel_obj} is same as {object_}, but {subject} is not {object_}")
                                
                                return VerificationResult(
                                    is_consistent=False,
                                    contradiction_type="transitivity_contradiction",
                                    contradicting_statements=[rel_stmt, eq_stmt, stmt],
                                    explanation=f"Transitivity contradiction: '{subject}' is '{rel_obj}', '{entity1}' and '{entity2}' are the same, but '{subject}' is not '{object_}'."
                                )
        
        logger.info(f"[FLOW:SAME] Added {len(rules)} rules for 'same' relationships")
        return rules 

    def _check_class_instance_contradictions(self, statements):
        """
        Check for contradictions involving class/instance relationships.
        
        This method looks for patterns like:
        - "X is a Y" and "X is not a Y"
        - "No Xs are Ys" but "Z is an X" and "Z is a Y"
        
        Args:
            statements (list): List of natural language statements to check
            
        Returns:
            VerificationResult: Result with consistency status and explanation
        """
        logger.info("[FLOW:CLASS_INSTANCE] Checking for class/instance contradictions")
        
        # Pattern for "X is a Y" or "X is an Y"
        is_pattern = re.compile(r"([A-Za-z0-9_\s]+?)\s+is\s+an?\s+([A-Za-z0-9_\s]+)", re.IGNORECASE)
        
        # Pattern for "X is not a Y" or "X is not an Y"
        is_not_pattern = re.compile(r"([A-Za-z0-9_\s]+?)\s+is\s+not\s+an?\s+([A-Za-z0-9_\s]+)", re.IGNORECASE)
        
        # Pattern for "No Xs are Ys"
        no_pattern = re.compile(r"No\s+([A-Za-z0-9_\s]+?)s?\s+are\s+([A-Za-z0-9_\s]+?)s?\.?", re.IGNORECASE)
        
        # Keep track of class memberships and non-memberships
        memberships = {}  # {entity: {class1, class2, ...}}
        non_memberships = {}  # {entity: {class1, class2, ...}}
        class_exclusions = {}  # {class1: {excluded_class1, excluded_class2, ...}}
        
        # Keep track of the original statements for reporting contradictions
        membership_statements = {}  # {(entity, class): statement}
        non_membership_statements = {}  # {(entity, class): statement}
        class_exclusion_statements = {}  # {(class1, class2): statement}
        
        # First pass: collect all relationships
        for stmt in statements:
            # Check for "X is a Y"
            for match in is_pattern.finditer(stmt):
                entity = match.group(1).strip()
                class_name = match.group(2).strip()
                
                if entity not in memberships:
                    memberships[entity] = set()
                memberships[entity].add(class_name)
                membership_statements[(entity, class_name)] = stmt
            
            # Check for "X is not a Y"
            for match in is_not_pattern.finditer(stmt):
                entity = match.group(1).strip()
                class_name = match.group(2).strip()
                
                if entity not in non_memberships:
                    non_memberships[entity] = set()
                non_memberships[entity].add(class_name)
                non_membership_statements[(entity, class_name)] = stmt
            
            # Check for "No Xs are Ys"
            for match in no_pattern.finditer(stmt):
                class1 = match.group(1).strip()
                class2 = match.group(2).strip()
                
                if class1 not in class_exclusions:
                    class_exclusions[class1] = set()
                class_exclusions[class1].add(class2)
                class_exclusion_statements[(class1, class2)] = stmt
        
        # Second pass: check for direct contradictions like "X is a Y" and "X is not a Y"
        for entity, classes in memberships.items():
            if entity in non_memberships:
                for class_name in classes:
                    if class_name in non_memberships[entity]:
                        logger.info(f"[FLOW:CLASS_INSTANCE] Found direct contradiction: {entity} is and is not a {class_name}")
                        return VerificationResult(
                            is_consistent=False,
                            explanation=f"Contradiction found: '{entity}' is both claimed to be and not be a {class_name}.",
                            contradiction_type="direct_class_contradiction",
                            contradicting_statements=[
                                membership_statements[(entity, class_name)],
                                non_membership_statements[(entity, class_name)]
                            ]
                        )
        
        # Third pass: check for contradictions involving class exclusions
        for entity, classes in memberships.items():
            for class_name in classes:
                if class_name in class_exclusions:
                    for excluded_class in class_exclusions[class_name]:
                        if excluded_class in classes:
                            logger.info(f"[FLOW:CLASS_INSTANCE] Found class exclusion contradiction: {entity} is a {class_name} and a {excluded_class}, but no {class_name}s are {excluded_class}s")
                            return VerificationResult(
                                is_consistent=False,
                                explanation=f"Contradiction found: '{entity}' is both a {class_name} and a {excluded_class}, but it was stated that no {class_name}s are {excluded_class}s.",
                                contradiction_type="class_exclusion_contradiction",
                                contradicting_statements=[
                                    membership_statements[(entity, class_name)],
                                    membership_statements[(entity, excluded_class)],
                                    class_exclusion_statements[(class_name, excluded_class)]
                                ]
                            )
        
        logger.info("[FLOW:CLASS_INSTANCE] No class/instance contradictions found")
        return VerificationResult(is_consistent=True) 